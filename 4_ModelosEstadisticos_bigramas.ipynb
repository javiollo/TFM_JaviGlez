{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este programa vamos a lanzar todos los modelos estadisticos y luego los vamos a evaluar conjuntamente.\n",
    "Vamos a lanzar varios modelos:\n",
    "    - Maximum Entropy\n",
    "    - SVM\n",
    "    - Logistic Regresion\n",
    "    - MultinomialNB\n",
    "    - SGDClassifier\n",
    "    - BernoulliNB\n",
    "    - Naive Bayes\n",
    "\n",
    "Y dentro de estos modelos, vamos a lanzarlos con la totalidad de los daots y luego con validacion cruzada de varios tamaños para ver cual es el modelo óptimo.\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Realizamos las importaciones de los paquetes que vamos a utilizar\n",
    "import collections\n",
    "import nltk.classify.util,nltk.metrics\n",
    "from nltk.classify import NaiveBayesClassifier, MaxentClassifier, SklearnClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB,BernoulliNB\n",
    "import csv\n",
    "from nltk import word_tokenize\n",
    "from sklearn.svm import LinearSVC, SVC, NuSVR, OneClassSVM\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "import random\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "import itertools\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.metrics import BigramAssocMeasures\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Leemos los ficheros con los datos tanto positivos como negativos\n",
    "posdata = []\n",
    "try:\n",
    "    with open('DATA_SALIDA/positivos.txt', 'rb') as myfile:    \n",
    "        reader = csv.reader(myfile, delimiter=',')\n",
    "        for val in reader:\n",
    "            posdata.append(val[0])\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Los negativos\n",
    "negdata = []\n",
    "try:\n",
    "    with open('DATA_SALIDA/negativos.csv', 'rb') as myfile:    \n",
    "        reader = csv.reader(myfile, delimiter=',')\n",
    "        for val in reader:\n",
    "            negdata.append(val[0])            \n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " #Definimos unas cuantas funciones que vamos a ir usando\n",
    "\n",
    "#Esta es para partir las palabras\n",
    "def word_split(data):    \n",
    "    data_new = []\n",
    "    for word in data:\n",
    "        word_filter = [i.lower() for i in word.split()]\n",
    "        data_new.append(word_filter)\n",
    "    return data_new\n",
    "\n",
    "def word_feats(words):    \n",
    "    return dict([(word, True) for word in words])\n",
    "\n",
    "#Creamos un diccionario con las stopwords en castellano\n",
    "stopset = set(stopwords.words('spanish'))\n",
    "\n",
    "#CReamos otrodiccionario con las palabras del texto pero eliminando las stopwords\n",
    "def stopword_filtered_word_feats(words):\n",
    "    #return dict([(word, True) for word in words if word not in stopset])\n",
    "    return dict([(word, True) for word in words if word not in stopset])\n",
    "    \n",
    "#CReamos bi-gramas con las palabras del texto\n",
    "def bigram_word_feats(words, score_fn=BigramAssocMeasures.chi_sq, n=200):\n",
    "    bigram_finder = BigramCollocationFinder.from_words(words)\n",
    "    bigrams = bigram_finder.nbest(score_fn, n)\n",
    "\n",
    "    return dict([(ngram, True) for ngram in itertools.chain(words, bigrams)])\n",
    "\n",
    "#Creamos bigramas con las palabras del texto pero eliminando las stopwords\n",
    "def bigram_word_feats_stopwords(words, score_fn=BigramAssocMeasures.chi_sq, n=200):\n",
    "    bigram_finder = BigramCollocationFinder.from_words(words)\n",
    "    bigrams = bigram_finder.nbest(score_fn, n)\n",
    "    \n",
    "    return dict([(ngram, True) for ngram in itertools.chain(words, bigrams) if ngram not in stopset])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculamos distintos parametros para los modelos\n",
    "\n",
    "def evaluate_classifier(featx):\n",
    "    \n",
    "    negfeats = [(featx(f), 'neg') for f in word_split(negdata)]\n",
    "    posfeats = [(featx(f), 'pos') for f in word_split(posdata)]\n",
    "    #Cortamos los ficheros\n",
    "    negcutoff = len(negfeats)*3/4\n",
    "    poscutoff = len(posfeats)*3/4\n",
    "    #Creamos los ficheros de train y test\n",
    "    trainfeats = negfeats[:negcutoff] + posfeats[:poscutoff]\n",
    "    testfeats = negfeats[negcutoff:] + posfeats[poscutoff:]\n",
    "    \n",
    "    # vamos a realizar 7 modelos\n",
    "    lista_modelos = ['nb', 'bnb', 'mnb', 'maxent', 'svm', 'glm', 'sgd']     \n",
    "        \n",
    "    for cl in lista_modelos:\n",
    "        if cl == 'maxent':\n",
    "            classifierName = 'Maximum Entropy'\n",
    "            classifier = MaxentClassifier.train(trainfeats, 'GIS', trace=0, encoding=None, labels=None, gaussian_prior_sigma=0, max_iter = 1)\n",
    "        elif cl == 'svm':\n",
    "            classifierName = 'SVM'\n",
    "            classifier = SklearnClassifier(LinearSVC(), sparse=False)\n",
    "            classifier.train(trainfeats)\n",
    "        elif cl == 'glm':\n",
    "            classifierName = 'Logistic Regresion'\n",
    "            classifier = SklearnClassifier(LogisticRegression())\n",
    "            classifier.train(trainfeats)\n",
    "        elif cl == 'mnb':\n",
    "            classifierName = 'MultinomialNB'\n",
    "            classifier = SklearnClassifier(MultinomialNB())\n",
    "            classifier.train(trainfeats)\n",
    "        elif cl == 'sgd':\n",
    "            classifierName = 'SGDClassifier'\n",
    "            classifier = SklearnClassifier(SGDClassifier(loss='hinge', penalty='l2', alpha=0.0001, l1_ratio=0.15, fit_intercept=True, max_iter=None, tol=None, shuffle=True, verbose=0, epsilon=0.1, n_jobs=1, random_state=None, learning_rate='optimal', eta0=0.0, power_t=0.5, class_weight=None, warm_start=False, average=False, n_iter=None))\n",
    "            classifier.train(trainfeats)\n",
    "        elif cl == 'bnb':\n",
    "            classifierName = 'BernoulliNB'\n",
    "            classifier = SklearnClassifier(BernoulliNB())\n",
    "            classifier.train(trainfeats)\n",
    "        else:\n",
    "            classifierName = 'Naive Bayes'\n",
    "            classifier = NaiveBayesClassifier.train(trainfeats)\n",
    "            #palabrasmasimportatesNB = classifier.show_most_informative_features(10)\n",
    "            \n",
    "        refsets = collections.defaultdict(set)\n",
    "        testsets = collections.defaultdict(set)\n",
    " \n",
    "        for i, (feats, label) in enumerate(testfeats):\n",
    "                refsets[label].add(i)\n",
    "                observed = classifier.classify(feats)\n",
    "                testsets[observed].add(i)\n",
    " \n",
    "        #Calculamos los estadisticos a mostrar: accuracy, precision, recall y f-measure\n",
    "        accuracy = nltk.classify.util.accuracy(classifier, testfeats)\n",
    "        pos_precision = nltk.precision(refsets['pos'], testsets['pos'])\n",
    "        pos_recall = nltk.recall(refsets['pos'], testsets['pos'])\n",
    "        pos_fmeasure = nltk.f_measure(refsets['pos'], testsets['pos'])\n",
    "        neg_precision = nltk.precision(refsets['neg'], testsets['neg'])\n",
    "        neg_recall = nltk.recall(refsets['neg'], testsets['neg'])\n",
    "        neg_fmeasure =  nltk.f_measure(refsets['neg'], testsets['neg'])\n",
    "        \n",
    "        #Mostramos los resultados\n",
    "        print ''\n",
    "        print '---------------------------------------'\n",
    "        print 'RESULTADO INDIVIDUAL ' + '(' + classifierName + ')'\n",
    "        print '---------------------------------------'\n",
    "        print 'accuracy:', accuracy\n",
    "        print 'precision:', (pos_precision + neg_precision) / 2\n",
    "        print 'recall:', (pos_recall + neg_recall) / 2\n",
    "        print 'f-measure:', (pos_fmeasure + neg_fmeasure) / 2   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Los mismos parametros pero con validacion cruzada de N partes\n",
    "def evaluate_classifier_cross_val(featx, npartes):   \n",
    "\n",
    "    negfeats = [(featx(f), 'neg') for f in word_split(negdata)]\n",
    "    posfeats = [(featx(f), 'pos') for f in word_split(posdata)]\n",
    "    #Cortamos los ficheros\n",
    "    negcutoff = len(negfeats)*3/4\n",
    "    poscutoff = len(posfeats)*3/4\n",
    "    #Creamos los ficheros de train y test \n",
    "    trainfeats = negfeats[:negcutoff] + posfeats[:poscutoff]\n",
    "    testfeats = negfeats[negcutoff:] + posfeats[poscutoff:]\n",
    "    \n",
    "    trainfeats = negfeats + posfeats    \n",
    "    \n",
    "    # Creamos un dataset aleatorio  \n",
    "    random.shuffle(trainfeats)    \n",
    "    n = npartes # Le pasamos el numero de partes por parámetro    \n",
    "    \n",
    "    lista_modelos = ['nb', 'bnb', 'mnb', 'maxent', 'svm', 'glm', 'sgd']  \n",
    "    \n",
    "    for cl in lista_modelos:\n",
    "        #Creamos unas listas vacias para ir rellenando cada vez que se ejecute un submodelo de la validacion cruzada\n",
    "        subset_size = len(trainfeats) / n\n",
    "        accuracy = []\n",
    "        pos_precision = []\n",
    "        pos_recall = []\n",
    "        neg_precision = []\n",
    "        neg_recall = []\n",
    "        pos_fmeasure = []\n",
    "        neg_fmeasure = []\n",
    "        cv_count = 1\n",
    "        for i in range(n):        \n",
    "            testing_this_round = trainfeats[i*subset_size:][:subset_size]\n",
    "            training_this_round = trainfeats[:i*subset_size] + trainfeats[(i+1)*subset_size:]\n",
    "            if cl == 'maxent':\n",
    "                classifierName = 'Maximum Entropy'\n",
    "                classifier = MaxentClassifier.train(trainfeats, 'GIS', trace=0, encoding=None, labels=None, gaussian_prior_sigma=0, max_iter = 1)\n",
    "            elif cl == 'svm':\n",
    "                classifierName = 'SVM'\n",
    "                classifier = SklearnClassifier(LinearSVC(), sparse=False)\n",
    "                classifier.train(trainfeats)\n",
    "            elif cl == 'glm':\n",
    "                classifierName = 'Logistic Regresion'\n",
    "                classifier = SklearnClassifier(LogisticRegression())\n",
    "                classifier.train(trainfeats) \n",
    "            elif cl == 'sgd':\n",
    "                classifierName = 'SGDClassifier'\n",
    "                classifier = SklearnClassifier(SGDClassifier(loss='hinge', penalty='l2', alpha=0.0001, l1_ratio=0.15, fit_intercept=True, max_iter=None, tol=None, shuffle=True, verbose=0, epsilon=0.1, n_jobs=1, random_state=None, learning_rate='optimal', eta0=0.0, power_t=0.5, class_weight=None, warm_start=False, average=False, n_iter=None))\n",
    "                classifier.train(trainfeats)                        \n",
    "            elif cl == 'mnb':\n",
    "                classifierName = 'MultinomialNB'\n",
    "                classifier = SklearnClassifier(MultinomialNB())\n",
    "                classifier.train(trainfeats)            \n",
    "            elif cl == 'bnb':\n",
    "                classifierName = 'BernoulliNB'\n",
    "                classifier = SklearnClassifier(BernoulliNB())\n",
    "                classifier.train(trainfeats)              \n",
    "            else:\n",
    "                classifierName = 'Naive Bayes'\n",
    "                classifier = NaiveBayesClassifier.train(trainfeats)\n",
    "                #palabrasmasimportatesNB = classifier.show_most_informative_features(10)\n",
    "                    \n",
    "            refsets = collections.defaultdict(set)\n",
    "            testsets = collections.defaultdict(set)\n",
    "            for i, (feats, label) in enumerate(testing_this_round):\n",
    "                refsets[label].add(i)\n",
    "                observed = classifier.classify(feats)\n",
    "                testsets[observed].add(i)\n",
    "            \n",
    "            #Calculamos los estadisticos a mostrar: accuracy, precision, recall y f-measure\n",
    "            cv_accuracy = nltk.classify.util.accuracy(classifier, testing_this_round)\n",
    "            cv_pos_precision = nltk.precision(refsets['pos'], testsets['pos'])\n",
    "            cv_pos_recall = nltk.recall(refsets['pos'], testsets['pos'])\n",
    "            cv_pos_fmeasure = nltk.f_measure(refsets['pos'], testsets['pos'])\n",
    "            cv_neg_precision = nltk.precision(refsets['neg'], testsets['neg'])\n",
    "            cv_neg_recall = nltk.recall(refsets['neg'], testsets['neg'])\n",
    "            cv_neg_fmeasure =  nltk.f_measure(refsets['neg'], testsets['neg'])\n",
    "\n",
    "            accuracy.append(cv_accuracy)\n",
    "            pos_precision.append(cv_pos_precision)\n",
    "            pos_recall.append(cv_pos_recall)\n",
    "            neg_precision.append(cv_neg_precision)\n",
    "            neg_recall.append(cv_neg_recall)\n",
    "            pos_fmeasure.append(cv_pos_fmeasure)\n",
    "            neg_fmeasure.append(cv_neg_fmeasure)\n",
    "            \n",
    "            cv_count += 1\n",
    "        \n",
    "        #Mostramos los resultados                \n",
    "        print '---------------------------------------'\n",
    "        print 'RESULTADO DE VALIDACIÓN CRUZADA CON ' + str(n) + ' partes: ' + '(' + classifierName + ')'\n",
    "        print '---------------------------------------'\n",
    "        print 'accuracy:', sum(accuracy) / n\n",
    "        print 'precision:', (sum(pos_precision)/n + sum(neg_precision)/n) / 2\n",
    "        print 'recall:', (sum(pos_recall)/n + sum(neg_recall)/n) / 2\n",
    "        print 'f-measure:', (sum(pos_fmeasure)/n + sum(neg_fmeasure)/n) / 2\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ejecutamos y evaluamos todos los modelos\n",
    "evaluate_classifier(bigram_word_feats)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ejecutamos y evaluamos todos los modelos con validacion cruzada\n",
    "evaluate_classifier_cross_val(bigram_word_feats, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ejecutamos y evaluamos el modelo filtrando las stop words\n",
    "evaluate_classifier(bigram_word_feats_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ejecutamos y evaluamos el modelo filtrando las stop words con validacion cruzada\n",
    "evaluate_classifier_cross_val(bigram_word_feats_stopwords, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
